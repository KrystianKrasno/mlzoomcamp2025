{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9f20f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa941009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lead_source', 'industry', 'employment_status', 'location']\n",
      "['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score', 'converted']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model from Weeks 3/4 \n",
    "\n",
    "df = pd.read_csv(\"course_lead_scoring.csv\")\n",
    "\n",
    "cat_features = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "print(cat_features)\n",
    "\n",
    "num_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(num_features)\n",
    "\n",
    "\n",
    "for col in cat_features:\n",
    "    df[col] = df[col].fillna('NA')\n",
    "\n",
    "for col in num_features:\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39ff115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check and remove 'converted' from numerical features list\n",
    "if 'converted' in num_features:\n",
    "    num_features.remove('converted')\n",
    "    \n",
    "# Check and remove 'converted' from categorical features list if it was mistakenly there\n",
    "if 'converted' in cat_features:\n",
    "    cat_features.remove('converted')\n",
    "\n",
    "# # Initiate the model\n",
    "all_features = cat_features +  num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e13767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions that train / run the model \n",
    "\n",
    "def train(df_train, y_train, C=1.0):\n",
    "    \"\"\"Trains the Logistic Regression model.\"\"\"\n",
    "    dicts = df_train[cat_features + num_features].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    # Using solver='liblinear' is important for C < 1.0 (though here C=1.0)\n",
    "    model = LogisticRegression(solver='liblinear', C=C, max_iter=1000) \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return dv, model\n",
    "\n",
    "def predict(df, dv, model):\n",
    "    \"\"\"Generates probability predictions on the given DataFrame.\"\"\"\n",
    "    dicts = df[cat_features + num_features].to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ef589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1.0 \n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadaf49c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_splits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m kfold = KFold(n_splits=\u001b[43mn_splits\u001b[49m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'n_splits' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in kfold.split(df_full_train): \n",
    "    df_train = df_full_train.iloc[train_idx]\n",
    "    df_val = df_full_train.iloc[val_idx]\n",
    "\n",
    "    y_train = df_train.converted.values\n",
    "    y_val = df_val.converted.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d31e80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
