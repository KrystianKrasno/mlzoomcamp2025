{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "d1a40f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lead_source</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>social_media</td>\n",
       "      <td>events</td>\n",
       "      <td>paid_ads</td>\n",
       "      <td>referral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <td>NaN</td>\n",
       "      <td>retail</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>retail</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>79450.0</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>85012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_status</th>\n",
       "      <td>unemployed</td>\n",
       "      <td>employed</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self_employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>south_america</td>\n",
       "      <td>south_america</td>\n",
       "      <td>australia</td>\n",
       "      <td>australia</td>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_count</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_score</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>converted</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0              1           2          3  \\\n",
       "lead_source                    paid_ads   social_media      events   paid_ads   \n",
       "industry                            NaN         retail  healthcare     retail   \n",
       "number_of_courses_viewed              1              1           5          2   \n",
       "annual_income                   79450.0        46992.0     78796.0    83843.0   \n",
       "employment_status            unemployed       employed  unemployed        NaN   \n",
       "location                  south_america  south_america   australia  australia   \n",
       "interaction_count                     4              1           3          1   \n",
       "lead_score                         0.94            0.8        0.69       0.87   \n",
       "converted                             1              0           1          0   \n",
       "\n",
       "                                      4  \n",
       "lead_source                    referral  \n",
       "industry                      education  \n",
       "number_of_courses_viewed              3  \n",
       "annual_income                   85012.0  \n",
       "employment_status         self_employed  \n",
       "location                         europe  \n",
       "interaction_count                     3  \n",
       "lead_score                         0.62  \n",
       "converted                             1  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# In this dataset our desired target for classification task will be converted variable - has the client signed up to the platform or not.\n",
    "\n",
    "df = pd.read_csv(\"course_lead_scoring.csv\")\n",
    "\n",
    "# print(df.head(5))\n",
    "# print(df.dtypes)\n",
    "\n",
    "df.head().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "51f5b4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1462 entries, 0 to 1461\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   lead_source               1334 non-null   object \n",
      " 1   industry                  1328 non-null   object \n",
      " 2   number_of_courses_viewed  1462 non-null   int64  \n",
      " 3   annual_income             1281 non-null   float64\n",
      " 4   employment_status         1362 non-null   object \n",
      " 5   location                  1399 non-null   object \n",
      " 6   interaction_count         1462 non-null   int64  \n",
      " 7   lead_score                1462 non-null   float64\n",
      " 8   converted                 1462 non-null   int64  \n",
      "dtypes: float64(2), int64(3), object(4)\n",
      "memory usage: 102.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "    # Check if the missing values are presented in the features.\n",
    "df.isnull().sum()\n",
    "df.info() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "58c35506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lead_source', 'industry', 'employment_status', 'location']\n",
      "['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score', 'converted']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If there are missing values:\n",
    "    # For categorical features, replace them with 'NA'\n",
    "    # For numerical features, replace with with 0.0\n",
    "\n",
    "cat_features = list(df.dtypes[df.dtypes == 'object'].index)\n",
    "print (cat_features)\n",
    "\n",
    "num_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "print(num_features)\n",
    "\n",
    "for col in cat_features: \n",
    "    df[col] = df[col].fillna('NA')\n",
    "\n",
    "for col in num_features:\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "\n",
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "36e803d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode for 'industry': retail\n",
      "{'interaction_count and lead_score': np.float64(0.009888182496913131), 'number_of_courses_viewed and lead_score': np.float64(-0.004878998354681276), 'number_of_courses_viewed and interaction_count': np.float64(-0.023565222882888037), 'annual_income and interaction_count': np.float64(0.02703647240481443)}\n",
      "Pair with the biggest correlation: annual_income and interaction_count\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "    # What is the most frequent observation (mode) for the column industry?\n",
    "\n",
    "most_freq = df['industry'].mode()[0]\n",
    "print(f\"Mode for 'industry': {most_freq}\")\n",
    "\n",
    "# Question 2\n",
    "# Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "corr_matrix = df[num_features].corr()\n",
    "\n",
    "# Check the correlation values for the specified pairs (absolute value indicates strength)\n",
    "corr_interaction_leadscore = corr_matrix.loc['interaction_count', 'lead_score']\n",
    "corr_courses_leadscore = corr_matrix.loc['number_of_courses_viewed', 'lead_score']\n",
    "corr_courses_interaction = corr_matrix.loc['number_of_courses_viewed', 'interaction_count']\n",
    "corr_annualincome_interaction = corr_matrix.loc['annual_income', 'interaction_count']\n",
    "\n",
    "# Create a dictionary to hold the absolute correlations\n",
    "abs_correlations = {\n",
    "    'interaction_count and lead_score': (corr_interaction_leadscore),\n",
    "    'number_of_courses_viewed and lead_score': (corr_courses_leadscore),\n",
    "    'number_of_courses_viewed and interaction_count': (corr_courses_interaction),\n",
    "    'annual_income and interaction_count': (corr_annualincome_interaction)\n",
    "}\n",
    "\n",
    "print(abs_correlations)\n",
    "\n",
    "# # Find the pair with the maximum absolute correlation\n",
    "biggest_correlation_pair = max(abs_correlations, key=abs_correlations.get)\n",
    "print(f\"Pair with the biggest correlation: {biggest_correlation_pair}\")\n",
    "\n",
    "# What are the two features that have the biggest correlation?\n",
    "    # interaction_count and lead_score\n",
    "    # number_of_courses_viewed and lead_score\n",
    "    # number_of_courses_viewed and interaction_count\n",
    "                # annual_income and interaction_count  *******answer \n",
    "    # Only consider the pairs above when answering this question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc275ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1462\n",
      "1169\n",
      "876\n",
      "293\n",
      "293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    " # Split the data\n",
    "    # Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "    # Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "    # Make sure that the target value converted is not in your dataframe.\n",
    "\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "\n",
    "df_train, df_val = train_test_split(df_full_train, test_size = 0.25, random_state=42)\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "print(len(df_full_train))\n",
    "print(len(df_train))\n",
    "print(len(df_test))   \n",
    "print(len(df_val))\n",
    "                                    \n",
    "# Separate target variables\n",
    "y_train = df_train[\"converted\"].values\n",
    "y_val = df_val[\"converted\"].values\n",
    "y_test = df_test[\"converted\"].values\n",
    "\n",
    "# Drop the target variable from feature dataframes\n",
    "df_train = df_train.drop(columns=[\"converted\"])\n",
    "df_val = df_val.drop(columns=[\"converted\"])\n",
    "df_test = df_test.drop(columns=[\"converted\"])         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "542355de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industry MI =  0.01\n",
      "location MI =  0.0\n",
      "lead_source MI =  0.03\n",
      "employment_status MI =  0.01\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "lead_source          0.02\n",
       "industry             0.01\n",
       "employment_status    0.01\n",
       "location             0.00\n",
       "dtype: float64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question 3\n",
    "    # Calculate the mutual information score between converted and other categorical variables in the dataset. Use the training set only.\n",
    "    # Round the scores to 2 decimals using round(score, 2).\n",
    "# Which of these variables has the biggest mutual information score?\n",
    "    # industry\n",
    "    # location\n",
    "          # lead_source  ** largest at 0.04 \n",
    "    # employment_status\n",
    "\n",
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "mi_industry = mutual_info_score(y_train, df_train.industry)\n",
    "mi_location = mutual_info_score(y_train, df_train.location)\n",
    "mi_lead_source = mutual_info_score(y_train, df_train.lead_source)\n",
    "mi_employment_status = mutual_info_score(y_train, df_train.employment_status)\n",
    "\n",
    "# The first time I did this I just used df_full_train on everything above and got a very similar answer (0.03 - lead_source) .. would this have been incorrect? \n",
    "\n",
    "print(\"industry MI = \", round(mi_industry,2))\n",
    "print(\"location MI = \", round(mi_location,2))\n",
    "print(\"lead_source MI = \", round(mi_lead_source,2))\n",
    "print(\"employment_status MI = \", round(mi_employment_status,2))\n",
    "\n",
    "\n",
    "# or ...\n",
    "\n",
    "\n",
    "def mutual_info_churn_score(series):\n",
    "    return mutual_info_score(series, df_full_train.converted)\n",
    "\n",
    "mi = df_full_train[cat_features].apply(mutual_info_churn_score).round(2)\n",
    "mi.sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47595ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.08556616376377484\n",
      "0.7304\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "# Now let's train a logistic regression.\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Check and remove 'converted' from numerical features list\n",
    "if 'converted' in num_features:\n",
    "    num_features.remove('converted')\n",
    "    \n",
    "# Check and remove 'converted' from categorical features list if it was mistakenly there\n",
    "if 'converted' in cat_features:\n",
    "    cat_features.remove('converted')\n",
    "\n",
    "# Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "all_features = cat_features +  num_features\n",
    "\n",
    "train_dicts = df_train[all_features].to_dict(orient='records') # For making dict row-wise we use orient = 'records\n",
    "val_dicts = df_val[all_features].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "# Fit the model on the training dataset.\n",
    "# To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "# model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "                # y_pred = model.predict_proba(X_val)[:,1]\n",
    "                # churn_decision = (y_pred >= 0.5)\n",
    "\n",
    "model = LogisticRegression(solver = 'liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n",
    "accuracy = (y_val == y_pred).mean()\n",
    "acc_round = round(accuracy, 4)\n",
    "original_accuracy = accuracy \n",
    "\n",
    "w0 = model.intercept_[0]\n",
    "print(w0)\n",
    "\n",
    "w = model.coef_[0]\n",
    "w.round(3)\n",
    "\n",
    "dict(zip(dv.get_feature_names_out(), w.round(3)))\n",
    "\n",
    "# Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "# What accuracy did you get?\n",
    "    # 0.64\n",
    "     # 0.74  ** this one is the closest but I get 0.7304 \n",
    "    # 0.84\n",
    "    # 0.94\n",
    "\n",
    "print(acc_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "85e8661a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy differences: {'industry': np.float64(-0.010238907849829393), 'employment_status': np.float64(0.0), 'lead_score': np.float64(0.0)}\n",
      "Feature with the smallest change (least useful): employment_status\n"
     ]
    }
   ],
   "source": [
    "# Question 5\n",
    "# Let's find the least useful feature using the feature elimination technique.\n",
    "# Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "# Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "# For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "    # Which of following feature has the smallest difference?\n",
    "    # 'industry'\n",
    "            # 'employment_status'  - Answer \n",
    "            # 'lead_score'  this is also 0.0 as the smallest difference... is this correct? \n",
    "    # Note: The difference doesn't have to be positive.\n",
    "\n",
    "# Question 5: Feature Elimination (Finding the least useful feature)\n",
    "features_to_check = ['industry', 'employment_status', 'lead_score']\n",
    "accuracy_differences = {}\n",
    "\n",
    "# Use the one-hot encoded feature names for exclusion\n",
    "full_features = set(dv.get_feature_names_out())\n",
    "\n",
    "for feature_to_exclude in features_to_check:\n",
    "    \n",
    "    # Identify which columns to keep (all features excluding the current one)\n",
    "    # This logic is simplified; for OHE, this would need to exclude ALL columns \n",
    "\n",
    "    current_features_df = [f for f in all_features if f != feature_to_exclude]\n",
    "    \n",
    "    # Re-vectorize on the reduced feature set\n",
    "    dv_subset = DictVectorizer(sparse=False)\n",
    "    X_train_subset = dv_subset.fit_transform(df_train[current_features_df].to_dict(orient='records'))\n",
    "    X_val_subset = dv_subset.transform(df_val[current_features_df].to_dict(orient='records'))\n",
    "    \n",
    "    # Train a new model with the subset\n",
    "    model_subset = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_subset.fit(X_train_subset, y_train)\n",
    "    \n",
    "    # Calculate new validation accuracy\n",
    "    y_pred_subset = model_subset.predict(X_val_subset)\n",
    "    accuracy_subset = (y_val == y_pred_subset).mean()\n",
    "    \n",
    "    # Calculate the difference (original accuracy - new accuracy)\n",
    "    diff = original_accuracy - accuracy_subset\n",
    "    accuracy_differences[feature_to_exclude] = diff\n",
    "\n",
    "\n",
    "# Find the feature with the smallest change (smallest absolute difference)\n",
    "# The \"least useful\" feature is the one whose removal causes the smallest absolute drop in performance.\n",
    "least_useful_feature = min(accuracy_differences, key=lambda k: abs(accuracy_differences[k]))\n",
    "\n",
    "print(f\"Accuracy differences: {accuracy_differences}\")\n",
    "print(f\"Feature with the smallest change (least useful): {least_useful_feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "30cda198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for each C: {0.01: np.float64(0.7304), 0.1: np.float64(0.7304), 1: np.float64(0.7304), 10: np.float64(0.7304), 100: np.float64(0.7304)}\n"
     ]
    }
   ],
   "source": [
    "# Question 6\n",
    "# Now let's train a regularized logistic regression.\n",
    "# Let's try the following values of the parameter C: [0.01, 0.1, 1, 10, 100].\n",
    "# Train models using all the features as in Q4.\n",
    "\n",
    "\n",
    "parameter_c = [0.01, 0.1, 1, 10, 100]\n",
    "accuracy_scores = {}\n",
    "\n",
    "for c in parameter_c:\n",
    "    model = LogisticRegression(solver='liblinear', C = c , max_iter=20000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = (y_val == y_pred).mean()\n",
    "    accuracy_scores[c] = round(accuracy,4)\n",
    "\n",
    "# Print all results to find the best C\n",
    "print(\"Accuracy scores for each C:\", accuracy_scores)\n",
    "\n",
    "# Find the C value with the highest accuracy\n",
    "best_c = max(accuracy_scores, key=accuracy_scores.get)\n",
    "\n",
    "# Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "# Which of these C leads to the best accuracy on the validation set?\n",
    "        # 0.01 - this should be the closest one \n",
    "# 0.1\n",
    "# 1\n",
    "# 10\n",
    "# 100\n",
    "# Note: If there are multiple options, select the smallest C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b40e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Accuracy Scores for each C:\n",
      "C=0.01 : 0.73037543\n",
      "C=0.1  : 0.73037543\n",
      "C=1    : 0.73037543\n",
      "C=10   : 0.73037543\n",
      "C=100  : 0.73037543\n",
      "[0.57225234 0.94760944 0.70570537 0.36663941 0.41823678 0.85255382\n",
      " 0.74743733 0.48268898 0.75544304 0.71296911 0.59343865 0.33730063\n",
      " 0.53399183 0.64826513 0.62104479 0.5161717  0.80676091 0.77287496\n",
      " 0.65057282 0.54980744 0.87676395 0.58514127 0.40470678 0.63606997\n",
      " 0.63949595 0.44136745 0.44509255 0.34487497 0.72547584 0.72741909\n",
      " 0.29958754 0.67105431 0.82811361 0.96043549 0.93631193 0.93637751\n",
      " 0.50570363 0.61381657 0.64192505 0.71477489 0.90748216 0.4870827\n",
      " 0.83938187 0.60022485 0.62711865 0.59993718 0.7352204  0.52521649\n",
      " 0.53371387 0.74175564 0.48976788 0.89816649 0.93749382 0.90816271\n",
      " 0.61654057 0.4356769  0.40061734 0.58189244 0.36149332 0.45652569\n",
      " 0.87265849 0.80960247 0.65846375 0.68398226 0.80925654 0.57398685\n",
      " 0.84387498 0.52784078 0.77842587 0.70672505 0.60522308 0.72735917\n",
      " 0.41979148 0.82703618 0.71495659 0.60481247 0.85282389 0.51635717\n",
      " 0.67072054 0.94018514 0.61060542 0.33032365 0.82037571 0.45714672\n",
      " 0.58442436 0.86243732 0.54129636 0.77120241 0.66953223 0.62210709\n",
      " 0.73722192 0.73503275 0.47172025 0.65943012 0.6487978  0.55650944\n",
      " 0.45995829 0.76004113 0.69258665 0.42464    0.87018915 0.6722439\n",
      " 0.60743088 0.46816827 0.60891918 0.87423634 0.62674938 0.4258577\n",
      " 0.78837767 0.73468757 0.39188362 0.47048548 0.67781446 0.42706273\n",
      " 0.87925487 0.8855232  0.62598749 0.80154775 0.8466644  0.72620874\n",
      " 0.62381945 0.3395505  0.88625385 0.66777702 0.78192543 0.71604145\n",
      " 0.7685583  0.89726356 0.68387595 0.8804416  0.94214821 0.71486623\n",
      " 0.76169514 0.81588184 0.66592772 0.28637245 0.61105607 0.58729583\n",
      " 0.63225276 0.53900086 0.42578837 0.76722536 0.3402997  0.78100092\n",
      " 0.72571044 0.62715486 0.63781185 0.70170497 0.86871408 0.60903675\n",
      " 0.55615141 0.72529597 0.48532627 0.61370115 0.80703658 0.84547002\n",
      " 0.93379096 0.80325151 0.5789474  0.46813059 0.70578337 0.45022044\n",
      " 0.36894158 0.67148338 0.77559079 0.48150848 0.57278012 0.82371641\n",
      " 0.80009622 0.55877635 0.79775332 0.90907827 0.68096101 0.58845264\n",
      " 0.40534011 0.35694362 0.78248602 0.62973931 0.57722496 0.36815552\n",
      " 0.51234077 0.22435347 0.91857522 0.63781305 0.61545851 0.57279969\n",
      " 0.74269372 0.6276897  0.50124094 0.58435439 0.3614296  0.45122757\n",
      " 0.95498958 0.64643237 0.69464411 0.44130509 0.73013044 0.92762457\n",
      " 0.60818579 0.48055991 0.32720066 0.73629688 0.71537934 0.82215875\n",
      " 0.65559359 0.49639185 0.67338692 0.79704515 0.95742272 0.75225791\n",
      " 0.86943239 0.8280436  0.73668367 0.68773297 0.71818629 0.68411871\n",
      " 0.77175898 0.80412512 0.47682544 0.86589318 0.51975708 0.33941786\n",
      " 0.89177023 0.80018241 0.43356924 0.56263015 0.50768261 0.71049706\n",
      " 0.55332092 0.64814996 0.84861075 0.25385444 0.72314051 0.47018479\n",
      " 0.54572801 0.72133193 0.35470893 0.73430405 0.8251282  0.61748326\n",
      " 0.48697985 0.74837174 0.79738892 0.71191311 0.60582678 0.590691\n",
      " 0.34726546 0.63145397 0.5571619  0.69539785 0.41255343 0.45975115\n",
      " 0.50761935 0.73180791 0.87221237 0.64038396 0.72343203 0.85822592\n",
      " 0.69610355 0.69397013 0.76331857 0.55704294 0.67871197 0.64351225\n",
      " 0.6638957  0.8340823  0.50795149 0.65602128 0.68948887 0.84695866\n",
      " 0.35934917 0.59160262 0.44053765 0.43295955 0.75394009 0.7570146\n",
      " 0.69973958 0.28475542 0.37894471 0.62893574 0.76545722 0.80461754\n",
      " 0.77638343 0.4163801  0.80985962 0.5730761  0.6420416  0.88138247\n",
      " 0.82629075 0.3435449  0.29040618 0.57072525 0.52346509]\n",
      "\n",
      "The C value that yields the highest accuracy is: 0.01\n"
     ]
    }
   ],
   "source": [
    "# LLM notes / code for experimentation below \n",
    "\n",
    "\n",
    "parameter_c = [0.01, 0.1, 1, 10, 100]\n",
    "accuracy_scores = {}\n",
    "threshold = 0.5 # The default threshold we are making explicit\n",
    "\n",
    "# Use the X_train and X_val from Question 4 (all features)\n",
    "\n",
    "for c in parameter_c:\n",
    "    # 1. Define the model with the current C value and high max_iter\n",
    "    model = LogisticRegression(solver='liblinear', C = c , max_iter=20000, random_state=42)\n",
    "    \n",
    "    # 2. Fit the model on the training data\n",
    "    model.fit(X_train, y_train) \n",
    "    \n",
    "    # --- EXPLICIT THRESHOLDING METHOD ---\n",
    "    # 3. Get the probability estimates for the positive class (index 1)\n",
    "    y_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # 4. Apply the 0.5 threshold and convert the boolean results to integers (0s and 1s)\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    # 5. Calculate the UNROUNDED accuracy\n",
    "    accuracy = (y_val == y_pred).mean()\n",
    "    \n",
    "    # 6. Store the result\n",
    "    accuracy_scores[c] = accuracy \n",
    "\n",
    "# Print all results with full precision to clearly see the differences\n",
    "print(\"Full Accuracy Scores for each C:\")\n",
    "for c, acc in accuracy_scores.items():\n",
    "    # Use high precision printing to reveal subtle differences\n",
    "    print(f\"C={c:<5}: {acc:.8f}\")\n",
    "\n",
    "\n",
    "print(y_proba) #added to check values \n",
    "\n",
    "# Find the C value with the highest accuracy\n",
    "best_c = max(accuracy_scores, key=accuracy_scores.get)\n",
    "print(f\"\\nThe C value that yields the highest accuracy is: {best_c}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
